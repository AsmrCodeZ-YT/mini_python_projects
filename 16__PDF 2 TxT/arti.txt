Journal of Building Engineering 63 (2023) 105444
Available online 26 October 2022
2352-7102/© 2022 Published by Elsevier Ltd.Predictive models for concrete properties using machine learning 
and deep learning approaches: A review 
Mohammad Mohtasham Moeina, Ashkan Saradarb,*, Komeil Rahmatic, 
Seyed Hosein Ghasemzadeh Mousavinejadb, James Bristowd, Vartenie Aramalie, 
Moses Karakouzianf 
aDepartment of Civil Engineering, Allameh Mohaddes Nouri University, Mazandaran, Nour, Iran 
bDepartment of Civil Engineering, University of Guilan, Rasht, Iran 
cDepartment of Engineering, Islamic Azad University, Some Sara Branch, Some Sara, Iran 
dUniversal Engineering Sciences, Las Vegas, NV, USA 
eCalifornia State University, Northridge, Los Angeles, USA 
fDepartment of Civil and Environmental Engineering and Construction, University of Nevada, Las Vegas, USA   
ARTICLE INFO
Keywords: 
Machine learning Deep learning Artificial neural network 
Mechanical properties ABSTRACT
Concrete is one of the most widely used materials in various civil engineering applications. Its 
global production rate is increasing to meet demand. Mechanical properties of concrete are 
among important parameters in designing and evaluating its performance. Over the past few decades, machine learning has been used to model real-world problems. Machine learning, as a 
branch of artificial intelligence, is gaining popularity in many scientific fields such as robotics, 
statistics, bioinformatics, computer science, and construction materials. Machine learning has many advantages over statistical and experimental models, such as optimal accuracy, high- performance speed, responsiveness in complex environments, and economic cost-effectiveness. 
Recently, more researchers are looking into deep learning, which is a group of machine 
learning algorithms, as a powerful method in matters of diagnosis and classification. Hence, this paper provides a review of successful ML and DL model applications to predict concrete me
-
chanical properties. Several modeling algorithms were reviewed highlighting their applications, performance, current knowledge gaps, and suggestions for future research. This paper will assist construction material engineers and researchers in selecting suitable and accurate techniques that 
fit their applications.   
1. Introduction
Concrete is the most widely used building material worldwide. With population growth and urbanization, the demand for concrete
is expected to reach 18 billion by 2050 [1–3]. In order to improve the design of concrete structures, it is necessary to gain a better 
understanding of 
concrete performance, relying on accurate evaluation of its mechanical properties. Among the various properties of 
concrete, compressive strength has been considered a direct indicator of performance. It is directly related to the safety and 
* Corresponding author. 
E-mail addresses: m.mohtasham.moein@gmail.com (M. Mohtasham Moein), ashkan.saradar@gmail.com (A. Saradar), rahmati.komeil@yahoo.com (K. Rahmati), 
h.mosavi@guilan.ac.ir (S.H. Ghasemzadeh Mousavinejad), jbristow@universalengineering.com (J. Bristow), vartenie.aramali@csun.edu (V. Aramali), mkar@unlv. 
nevada.edu (M. Karakouzian).  
Contents lists available at ScienceDirect 
Journal of Building Engineering 
journal homepage: www.elsevier.com/locate/jobe 
https://doi.org/10.1016/j.jobe.2022.105444 
Received 10 August 2022; Received in revised form 5 October 2022; Accepted 18 October 2022   
e-tarjome.comJournal
of Building Engineering 63 (2023) 105444
2performance of the structure throughout its life cycle [1,4,5]. 
Concrete is a complex system of combinations of different components (coarse and fine aggregates, water, cement, and additional 
mixtures) that are randomly distributed throughout the concrete matrix [6–9]. This heterogeneous feature makes it difficult to 
accurately predict certain mechanical properties, especially compressive strength [10–12]. The most direct way to evaluate the 
compressive strength of concrete is through physical tests performed on specimens cured to the desired age [13,14]. Such a method for 
evaluating the compressive strength needs time while being affected by other factors related to specimen fabrications and test op -
erators. Moreover, the test tends to damage the specimens. Empirical regression methods were therefore proposed to predict compressive strength [15–17], but the disadvantage of this method is the non-linear relationship between the concrete mixture and the 
concrete’s compressive strength. This prevents an accurate regression expression. Numerical simulation is another method that can 
predict the behavior of concrete. However, a good prediction of concrete behavior is not easy to achieve due to the non-linearity and 
randomness [18–20]. 
In recent years, with the advances in the field of artificial intelligence, the trend of using machine learning methods, as well as deep 
learning (a branch of machine learning), to predict the mechanical properties of concrete has received much attention. Compared to 
traditional regression methods, it has special algorithms that can learn from data and display more accurate results as output data 
[21–23]. Machine learning is used in structural engineering in various fields seismic performance evaluation [24], tensile strength 
modeling [25] and compressive strength [26], structural system identification [27], and vibration control [28], to name a few. 
This article reviews the successful application of the machine and deep learning methods to predict the mechanical properties of 
concrete. We investigate the prediction accuracy of different algorithms used in the field of civil engineering on concrete properties 
was investigated and compared them to evaluate the performance of each algorithm. 
2. Artificial intelligence, machine learning, and deep learning
2.1. Artificial intelligence 
Nowadays, 
artificial intelligence, defined as the “study and design of intelligent agents,” significantly influences the world. These 
intelligent agents are systems that have the ability to understand the environment and take steps to maximize their chances of 
achieving success [29,30]. For example, smartphones and self-driving cars are among the advancements that have arisen due to 
upgrades in artificial intelligence [31]. 
With the advent of computers in the 50’s, huge changes took place in this field. Although it is difficult to pinpoint the origin of 
artificial intelligence, a turing point in this field can be attributed to Alan Turing’s paper entitled, “Computing Machinery and In -
telligence” [32,33]. Today, due to the upgrade and improvement of computing power and the dramatic increase of Big Data, this field 
has expanded substantially [33]. 
Early artificial intelligence applications targeted problems based on rules that are intellectually simple for the computer but 
challenging for humans. In order to solve such problems, a list of encrypted expressions “if and else” was introduced to the computer 
[34]. Many machines equipped with artificial intelligence have used this knowledge-based approach to go beyond human ability in abstract fields [35]. AI-based systems, however, were not without flaws and, in many cases, did not perform well. They struggled to 
perform everyday tasks, such as recognizing objects or understanding speech, that seem simple to a normal human [36]. As a result, 
modern artificial intelligence systems have struggled to find alternative ways of teaching intuition to computers [37]. Machine 
learning was brought to artificial intelligence systems to overcome the aforementioned challenges [36,38]. 
Machine learning began to flourish as a branch of artificial intelligence in the 1990s (Fig. 1). Instead of using symbolic approaches, 
it utilizes methods and models derived from statistics and probability theory [39,40]. In fact, machine learning algorithms allow 
machines to acquire the knowledge they need to perform a particular task by analyzing a sufficient number of data samples [38,41]. 
Before using the algorithm, it is necessary to perform a step called feature extraction, in which the attributes that represent the most 
specific information are extracted. The next step of the process, the sample data, is based on a specific ML training method to train the system to communicate the features and separate the patterns [33,36,42]. 
Deep Learning methods were introduced to solve the problems of the hand-crafted features in complex ML programs [36]. In-depth 
learning is inspired by advances in neuroscience and is consistent with interpretation information processing and communication 
patterns in the nervous system. Layers used in deep learning include the hidden layers of an artificial neural network and a set of 
Fig. 1. Knowledge-based relationship between AI, ML, DL.  M. Mohtasham Moein et al.                                                 Journal
of Building Engineering 63 (2023) 105444
3complex formulas [43,44]. Fig. 2 compares system performance in three fields: AI, ML, and DL. 
2.2. Machine learning 
The use of computer-aided modeling to predict the mechanical properties of building materials is growing [45]. Machine learning is 
a major branch of artificial intelligence that deals with the design and development of algorithms capable of identifying complex 
patterns of experimental data without considering a predetermined equation as a model and making intelligent decisions [46,47]. In 
general, the goal of machine learning is to build computer systems that learn from experience and can adapt to their environments. 
Important examples of machine learning include data mining (such as searching for information on the web) and implementing difficult software systems, such as automatic driving. Machine learning-based models can make predictions and describe knowledge 
acquisition from data [48,49]. Machine learning’s scope and potential are much broader than AI and encompass many disciplines, 
including information theory, probability, statistics, psychology and neurobiology, computational control complexity, theory, and 
philosophy [50]. Researchers evaluate machine learning algorithms by solution accuracy, solution quality, and performance speed 
[51]. 
Generally, the development of an ML model involves a small number of design choices: (i) the type of learning experience, (ii) 
learning goal performance, (iii) displaying target performance; and (iv) an algorithm for learning the objective performance of 
instructional examples. Moreover, ML is divided into supervised learning, unsupervised, semi-supervised, and reinforced depending on 
the training resources [52,53]. Supervised and unsupervised learning are the most common types of machine learning in several 
applications, including engineering [51]. In supervised learning, there is a set of learning examples, which for each input, output value, 
or function is also specified. The learning system aims to obtain a hypothesis that guesses the function or relationship between input 
and output. But in unsupervised learning, there is a set of learning examples in which only the amount of inputs is known, and no 
information about the correct output is available. Unsupervised learning is used to group inputs or predict the next value based on the 
current situation [46,51,54,55]. The common types of supervised and unsupervised algorithms used in machine learning are shown in 
Fig. 3. 
The tasks of machine learning systems can be summarized as follows [46,51,54–56]: 1) Classification: the goal of this step is to 
identify the category to which the input belongs, 2) Regression: The output format at this stage is considered as the difference with the 
classification stage. This step aims to model the relationships between the inputs and numerical outputs, 3) Prediction: The goal is to 
predict future values over a determined period of time. This step is a special type of regression, 4) Clustering: to extract similar points 
between two or more data sets. Clustering is performed according to an unsupervised method, instead of the tasks defined for the three previous steps (classification, regression, and prediction), which are performed based on supervised methods. Before starting data 
analysis by machine learning algorithms, one of the most important things is data normalization. Data normalization is one of the most 
common activities in machine learning. Among the advantages of data normalization, we can mention the improvement of gradient 
descent performance on normalized data compared to non-normalized data [57–61]. 
2.3. Deep learning 
Deep Learning (Deep Neural Learning or Deep Neural Network) methods were introduced to solve the problems of hand-crafted 
features in complex ML programs [33,36]. DL is a subset of ML artificial intelligence, which operates with networks that can learn 
unsupervised, unstructured data. DL is a special type of ML method that can extract the optimal input directly from raw data without 
user intervention. Thus, DL algorithms can support both the relationships of features to the desired output and the feature extraction 
process [36,62–64]. Finally, the DL system, with proper training, can find the direct mapping from primary or raw inputs to the target 
outputs without extracting features. It can also find the abstract (i.e., high level) features as a hierarchy that explains simple (i.e., low 
level) learned features. This capability allows DL algorithms to break complex tasks into simple problems and solve them [33,36,41, 
Fig. 2. Comparison of performance between AI, ML, DL.  M. Mohtasham Moein et al.                                                 Journal
of Building Engineering 63 (2023) 105444
465]. 
2.4. ML/Support vector machine (SVM) 
A support vector machine (SVM) is one of the supervised learning methods used for both classification and information regression 
[66]. Fig. 4 shows the network structure of the SVM. 
The SVM is a two-class classifier that separates classes by a linear boundary. The samples closest to the decision boundary are called 
support vectors. These vectors determine the equation of the decision boundary. This method is applied due to the structural risk 
minimization principle, which is applied by maximizing the distance between two transient hyperplanes from the support vectors of 
both classes. In order to be easy to understand and to express the theory of support vector, the simplest possible case for the classi -
fication of two classes of inseparable mode is started linearly [67,68]. Based on this principle, SVM has two salient features that lead to fruitful predictions a) excellent generalizability and b) compatibility with scattered and low data [69]. SVMs have been successfully 
implemented for a variety of purposes, such as error detection [70], image retrieval [71], and text recognition [72]. 
2.4.1. SVM development process (linear and non-linear) 
Fig. 5 shows the segmentation of data by the SVM. This method aims to maximize the margin, which indicates the distance from the 
hyperplane to the nearest point of each class to achieve better classification performance in the test data [73]. 
The original SVM algorithm was invented by Vepnik in 1963 and was generalized to a nonlinear model in 1995 by Vepnik and Kurtz 
[73]. This method is one of the relatively newer methods that, in recent years, has shown good efficiency in predicting the mechanical 
properties of concrete. Fig. 6 shows the transfer of data from two-dimensional to three-dimensional space. In most cases, the data 
presented to the model for classification are not linearly separable. In such cases, the backup vector machine uses a nonlinear imager to transfer the data to a higher-dimensional space. With this new dimension, this method searches for a hyperplane that separates data. 
With a nonlinear viewfinder suitable for transferring data to a high-dimensional space, the backup vector machine can always separate 
two data groups. 
Different kernel functions can be used to determine the output of nonlinear space. The most commonly used kernel functions are 
polynomial, sigmoid, radial, exponential, and linear functions. Table 1 shows a summary of kernels and their equations [67,74]. 
In general, the SVM method [67,74]: 1) 1) significantly more accurate and stronger, 2) less prone to overfitting compared to other 
models, 3) ability to model complex nonlinear decision boundaries, 4) implementation capacity in pattern recognition, classification, 
and regression. 
Fig. 3. Variety of commonly used machine learning algorithms.  
Fig. 4. Network of support vector machine [67].  M. Mohtasham Moein et al.                                                 